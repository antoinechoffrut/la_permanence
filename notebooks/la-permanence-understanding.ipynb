{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seat availability at La Permanence: a first look at the data\n",
    "\n",
    "[La Permanence](https://www.la-permanence.com) is a coworking space with two locations in Paris (*rue du Fer à Moulin* and *rue d'Alésia*).  Our purpose in this repository is to model and then predict the number the available seats, and this will be done in separate notebooks.  In this notebook, our goal is simply to familiarize ourselves with the data.  The steps taken in this notebook will be performed as a preliminary to most other notebooks, without explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timezones\n",
    "tz_utc = pytz.timezone(\"UTC\")  # timestamp is in UTC standard\n",
    "tz_paris = pytz.timezone(\"Europe/Paris\")  # locations are in Paris, France\n",
    "\n",
    "# Resampling rule: resolution of time regularization\n",
    "RESOL = 2  # 10\n",
    "RULE = f\"{RESOL}T\"\n",
    "# Duration of validation data\n",
    "ONE_HOUR = 60 // RESOL\n",
    "ONE_DAY = 24*ONE_HOUR\n",
    "ONE_WEEK = 7*ONE_DAY\n",
    "TWO_WEEKS = 2*ONE_WEEK\n",
    "days_of_the_week = {0: 'Monday',\n",
    "                    1: 'Tuesday', \n",
    "                    2: 'Wednesday',\n",
    "                    3: 'Thursday',\n",
    "                    4: 'Friday',\n",
    "                    5: 'Saturday', \n",
    "                    6: 'Sunday'}\n",
    "\n",
    "# Plotting\n",
    "SAVEFIGS = False\n",
    "FIGSIZE = (16, 6)\n",
    "ALPHA = 0.7\n",
    "# Colors \n",
    "COL_ALESIA = plt.rcParams['axes.prop_cycle'].by_key()['color'][0]\n",
    "COL_MOULIN = plt.rcParams['axes.prop_cycle'].by_key()['color'][1]\n",
    "COL_TRAIN = plt.rcParams['axes.prop_cycle'].by_key()['color'][2]\n",
    "COL_VALID = plt.rcParams['axes.prop_cycle'].by_key()['color'][3]\n",
    "COL_PREDICT = plt.rcParams['axes.prop_cycle'].by_key()['color'][4]\n",
    "COL_AVG = plt.rcParams['axes.prop_cycle'].by_key()['color'][5]\n",
    "COL_MED = plt.rcParams['axes.prop_cycle'].by_key()['color'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(df, n):\n",
    "    return df[:n].copy(), df[n:].copy()\n",
    "\n",
    "\n",
    "def new_y_ticklabel(text):\n",
    "    \"\"\"Reformat text for y ticklabels in heatmaps\"\"\"\n",
    "    ts = pd.to_datetime(text.get_text()).tz_localize(tz_utc).tz_convert(tz_paris)\n",
    "    return ts.strftime('%d %b %Y | %a') if ts.weekday() == 0 else ts.strftime('%a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: loading and preparation\n",
    "The dataset is saved in a `csv` file located in `~/Projects/la_permanence/attendance.csv`.  \n",
    "\n",
    "**Note**: `attendance.csv` is a misnomer, as the file actually records the number of *available* seats, rather than the number of seats used.  \n",
    "\n",
    "## Metadata on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size:          1MB\n",
      "Number of rows:     65844\n",
      "Names of columns:   timestamp, Moulin, Alésia\n"
     ]
    }
   ],
   "source": [
    "filename = 'attendance.csv'\n",
    "foldername = 'Projects/la_permanence'\n",
    "filepath = os.path.join(os.path.expanduser(\"~\"), foldername, filename)\n",
    "filesize = os.path.getsize(filepath)\n",
    "\n",
    "COL_WIDTH = 20  \n",
    "# for display in this cell\n",
    "\n",
    "if filesize > 1e6:\n",
    "    print(\"{0}{1:d}MB\".format(\"File size:\".ljust(COL_WIDTH), filesize//int(1e6)))\n",
    "elif filesize > 1e3:\n",
    "    print(\"{0}{1:d}KB\".format(\"File size:\".ljust(COL_WIDTH), filesize//int(1e3)))\n",
    "else:\n",
    "    print(\"{0}{1:d}B\".format(\"File size:\".ljust(COL_WIDTH), filesize))\n",
    "\n",
    "line_number = !wc -l < {filepath}\n",
    "line_number = int(line_number[0])\n",
    "print(\"{0}{1}\".format(\"Number of rows:\".ljust(COL_WIDTH), line_number))\n",
    "first_row = !head -1 {filepath}\n",
    "column_names = first_row[0].split(',')\n",
    "print(\"{0}{1}\".format(\"Names of columns:\".ljust(COL_WIDTH), \", \".join(column_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More details on the columns\n",
    "- `timestamp` gives the date and time (UTC) of data collection in the format `YYYY-MM-DD-hh-mm-ss` where \n",
    "  - `YYYY=`year,\n",
    "  - `MM=`month,\n",
    "  - `DD=`day,\n",
    "  - `hh=`hour,\n",
    "  - `mm=`minute,\n",
    "  - `ss`=second;\n",
    "- `Moulin` gives the number of available seats at the *rue du Fer à Moulin* location (maximum is 63);\n",
    "- `Alésia` gives the number of available seats at the *rue d'Alésia* location (maximum is 82).  \n",
    "\n",
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot safely convert passed user dtype of uint8 for float64 dtyped data in column 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array from dtype('float64') to dtype('uint8') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e631e0c51801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Moulin'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Alésia'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdateparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot safely convert passed user dtype of uint8 for float64 dtyped data in column 1"
     ]
    }
   ],
   "source": [
    "%time\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "raw_data = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=',',\n",
    "    dtype={'Moulin': np.uint8, 'Alésia': np.uint8},\n",
    "    parse_dates=['timestamp'],\n",
    "    date_parser=dateparse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting for timezones\n",
    "\n",
    "The `timestamp` values are in the UTC standard, while the coworking spaces are located in Paris, France:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "raw_data['timestamp'] = raw_data['timestamp'].apply(lambda ts: ts.tz_localize(tz_utc).tz_convert(tz_paris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time regularization\n",
    "\n",
    "The data was collected at irregular times, as can be seen by zooming in on a short window frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "idxs = range(100, 200)\n",
    "window = raw_data.loc[idxs, raw_data.columns]\n",
    "the_day = window.loc[window.index.min(), 'timestamp']\n",
    "the_hours = list(set([x.hour for x in  window.loc[idxs, 'timestamp']]))\n",
    "\n",
    "hour_range = pd.date_range(pd.Timestamp(the_day.year, the_day.month, the_day.day, the_day.hour), periods=the_hours[-1] - the_hours[0], freq= 'H')\n",
    "\n",
    "window.set_index('timestamp').plot(style='-o', **{\"markersize\": 3, \"markerfacecolor\": \"k\", \"markeredgecolor\": \"k\"}, alpha=ALPHA, ax=ax);\n",
    "\n",
    "ax.set_title(\"Seat availability at La Permanence coworking spaces\", fontsize=18);\n",
    "\n",
    "ax.set_ylabel(\"Number of available seats\", fontsize=14);\n",
    "ax.set_yticks(range(0, 80, 10));\n",
    "\n",
    "ax.set_xlabel(the_day.strftime('%A %d %B %Y'), fontsize=14);\n",
    "ax.set_xticks(hour_range);\n",
    "ax.set_xticklabels([x.strftime(\"%H:00\") for x in hour_range]);\n",
    "\n",
    "ax.legend([\"rue du Fer à Moulin\", \"rue d'Alésia\"]);\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we resample (at a resolution specified in `RULE`) and interpolate to regularize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.set_index(\"timestamp\", inplace=True)\n",
    "raw_data = raw_data.resample(RULE).mean().interpolate().round().astype(np.uint8)\n",
    "raw_data.reset_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional datetime features\n",
    "For future use we extract now additional features from the `timestamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time \n",
    "raw_data['Date'] = raw_data['timestamp'].apply(\n",
    "    lambda ts: pd.Timestamp(ts.year, ts.month, ts.day).tz_localize(tz_paris)\n",
    ")\n",
    "\n",
    "attributes = ['Dayofweek', 'Hour', 'Minute', 'Week']\n",
    "for attr in attributes:\n",
    "    raw_data[attr] = getattr(raw_data['timestamp'].dt, attr.lower())\n",
    "raw_data['Minuteofday'] = 60*raw_data['Hour'] + raw_data['Minute']\n",
    "raw_data['Minuteofweek'] = 24*60*raw_data['Dayofweek'] + raw_data['Minuteofday']\n",
    "print(\"\\nColumn names:\\n\\n{0}\".format(\"\\n\".join(raw_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation split\n",
    "We wil\n",
    "l shortly derive average values of the data, which can be used to make forecasts.  Thus we will work on a training dataset obtained by removing the last week's worth of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = ONE_WEEK\n",
    "n_trn = raw_data.shape[0] - n_valid\n",
    "train_data, valid_data = split_vals(raw_data, n_trn)\n",
    "train_timestamps, valid_timestamps = split_vals(raw_data[['timestamp']], n_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 4));\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6)\n",
    "\n",
    "ts_min = raw_data['timestamp'].min()\n",
    "ts_max = raw_data['timestamp'].max()\n",
    "the_date_range = pd.date_range(ts_min.date(), ts_max.date());\n",
    "\n",
    "# rue du Fer à Moulin\n",
    "raw_data.plot(x='timestamp', y='Moulin', color=COL_MOULIN, alpha=ALPHA, ax=ax);\n",
    "\n",
    "ax.set_title(\"Seat availability (rue du Fer à Moulin)\", fontsize=18)\n",
    "\n",
    "ax.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax.set_yticks(range(0, 80, 10))\n",
    "\n",
    "ax.axes.get_xaxis().label.set_visible(False);\n",
    "ax.set_xticks(the_date_range);\n",
    "ax.set_xticklabels([pd.to_datetime(x).strftime(\"%a %d %b\")  #  %d %b %Y | %A\n",
    "                     if x.weekday() in [0]\n",
    "                     else pd.to_datetime(x).strftime(\"%a\")\n",
    "                     for x in the_date_range])\n",
    "ax.tick_params(axis='x', labelrotation=60)\n",
    "\n",
    "ax.get_legend().remove();\n",
    "ax.grid();\n",
    "if SAVEFIGS:\n",
    "    plt.savefig(\"moulin-availability-timeseries.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging\n",
    "\n",
    "Now we derive a representative for each day of the week.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moulin = train_data.set_index('timestamp').drop('Alésia', axis=1)\n",
    "moulin_by_day_of_week = pd.pivot_table(moulin, index=moulin.index.hour, columns=moulin.index.dayofweek, values='Moulin', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "moulin_by_day_of_week.plot(alpha=ALPHA, ax=ax);\n",
    "\n",
    "ax.set_title(\"Average seat availability (rue du Fer à Moulin)\", fontsize=18)\n",
    "ax.set_ylabel(\"Available seats\", fontsize=14)\n",
    "ax.set_xlabel(\"Time of day\", fontsize=14)\n",
    "\n",
    "ax.set_yticks(range(0, 80, 10))\n",
    "ax.set_xticks(range(0,24, 3))\n",
    "ax.set_xticklabels([\"{:02d}:00\".format(x) for x in ax.get_xticks()])\n",
    "\n",
    "ax.legend(days_of_the_week.values())\n",
    "ax.grid()\n",
    "if SAVEFIGS:\n",
    "    plt.savefig(\"moulin-average-by-day.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the different days of the week have distinct average behaviour.  Is there a lot of variation about these representatives?  Can we have a sense of the distribution of the seat availability over the different weeks of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate plots\n",
    "\n",
    "We will now superpose plots of the data over entire days and weeks.  To this end we generate pivot tables.\n",
    "\n",
    "## Daily view\n",
    "Rearrange the (entire) dataset, one day per row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pivot = pd.pivot_table(raw_data, index='Date', columns='Minuteofday', values='Moulin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE);\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color'][0:7]\n",
    "ax.set_prop_cycle('color', colors)\n",
    "daily_pivot.transpose().plot(style='-', linewidth=4, alpha=0.3, ax=ax);\n",
    "\n",
    "ax.set_title(\"Seat availability: daily view (rue du Fer à Moulin)\", fontsize=18);\n",
    "\n",
    "ax.set_xticks([h*ONE_HOUR*RESOL for h in range(0, 24)])\n",
    "ax.set_xticklabels([\"{0:02d}:00\".format(x//ONE_HOUR//RESOL) for x in ax.get_xticks()])\n",
    "ax.set_xlabel(\"Time of day\", fontsize=14);\n",
    "\n",
    "ax.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax.set_yticks(range(0, 80, 10));\n",
    "\n",
    "\n",
    "ax.legend(days_of_the_week.values(), loc='lower left');\n",
    "ax.grid();\n",
    "if SAVEFIGS:\n",
    "    plt.savefig('moulin-daily-availability.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite difficult to get a sense of what is going on.  Things are a bit more instructive when looking at entire weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly view\n",
    "Rearrange the (training and validation) datasets, one week per row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_train_pivot = pd.pivot_table(train_data, index='Week', columns='Minuteofweek', values='Moulin')\n",
    "weekly_valid_pivot = pd.pivot_table(valid_data, index='Week', columns='Minuteofweek', values='Moulin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_valid_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate weekly averages over training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_train_avg = train_data.groupby('Minuteofweek')[['Moulin']].mean().round().astype(np.int8).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we plot the training data (in green), its average (in black), and the data for the last week of the validation set (in red):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), sharex=True);\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=COL_TRAIN, lw=4),\n",
    "                Line2D([0], [0], color=COL_VALID, lw=4),\n",
    "                Line2D([0], [0], color=COL_AVG, lw=4)]\n",
    "\n",
    "ax1.set_prop_cycle('color', colors)\n",
    "\n",
    "weekly_train_pivot.transpose().plot(style='-', linewidth=5, color=COL_TRAIN, alpha=0.2, ax=ax1);\n",
    "if weekly_valid_pivot.shape[0] > 1:\n",
    "    weekly_valid_pivot.iloc[-2].plot(style='-', linewidth=2, color=COL_VALID, alpha=1, ax=ax1);\n",
    "ax1.plot(weekly_train_avg['Minuteofweek'], weekly_train_avg['Moulin'], COL_AVG, alpha=ALPHA);\n",
    "\n",
    "ax1.set_title(\"Seat availability: weekly view (rue du Fer à Moulin)\", fontsize=18);\n",
    "\n",
    "ax1.set_xticks([d*ONE_DAY*RESOL for d in range(0, 7)])\n",
    "ax1.set_xticklabels(days_of_the_week.values());\n",
    "ax1.set_xlabel(\"Day of week\", fontsize=14);\n",
    "ax1.tick_params(axis='x', labelrotation=90);\n",
    "\n",
    "ax1.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax1.set_yticks(range(0, 80, 10));\n",
    "\n",
    "# ax1.get_legend().remove();\n",
    "# ax1.legend(['])\n",
    "ax1.legend(custom_lines, ['training', 'validation', 'average'], loc='upper left');\n",
    "ax1.grid();\n",
    "\n",
    "ax2.set_prop_cycle('color', colors)\n",
    "\n",
    "weekly_train_pivot.transpose().plot(style='-', linewidth=5, color=COL_TRAIN, alpha=0.2, ax=ax2);\n",
    "weekly_valid_pivot.iloc[-1].plot(style='-', linewidth=2, color=COL_VALID, alpha=1, ax=ax2);\n",
    "ax2.plot(weekly_train_avg['Minuteofweek'], weekly_train_avg['Moulin'], color=COL_AVG, alpha=ALPHA);\n",
    "\n",
    "ax2.set_xticks([d*ONE_DAY*RESOL for d in range(0, 7)])\n",
    "ax2.set_xticklabels(days_of_the_week.values());\n",
    "ax2.set_xlabel(\"Day of week\", fontsize=14);\n",
    "ax2.tick_params(axis='x', labelrotation=90);\n",
    "\n",
    "ax2.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax2.set_yticks(range(0, 80, 10));\n",
    "\n",
    "ax2.legend(custom_lines, ['training', 'validation', 'average'], loc='upper right');\n",
    "ax2.grid();\n",
    "\n",
    "if SAVEFIGS:\n",
    "    plt.savefig('moulin-weekly-timeseries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot gives some visual evidence that the training data (in green) is well represented by its average (in black).  The deviation seems to be due to a few outlying values (some of which are actually interpolated values replacing missing data).  The validation set turns out to be quite distinct from the previous weeks, and it is not too surprising that the average does not predict it very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_train_med = train_data.groupby('Minuteofweek')[['Moulin']].median().round().astype(np.int8).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), sharex=True);\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=COL_TRAIN, lw=4),\n",
    "                Line2D([0], [0], color=COL_VALID, lw=4),\n",
    "                Line2D([0], [0], color=COL_MED, lw=4)]\n",
    "\n",
    "ax1.set_prop_cycle('color', colors)\n",
    "\n",
    "weekly_train_pivot.transpose().plot(style='-', linewidth=5, color=COL_TRAIN, alpha=0.2, ax=ax1);\n",
    "if weekly_valid_pivot.shape[0] > 1:\n",
    "    weekly_valid_pivot.iloc[-2].plot(style='-', linewidth=2, color=COL_VALID, alpha=1, ax=ax1);\n",
    "ax1.plot(weekly_train_med['Minuteofweek'], weekly_train_med['Moulin'], color=COL_MED, alpha=ALPHA);\n",
    "\n",
    "ax1.set_title(\"Seat availability: weekly view (rue du Fer à Moulin)\", fontsize=18);\n",
    "\n",
    "ax1.set_xticks([d*ONE_DAY*RESOL for d in range(0, 7)])\n",
    "ax1.set_xticklabels(days_of_the_week.values());\n",
    "ax1.set_xlabel(\"Day of week\", fontsize=14);\n",
    "ax1.tick_params(axis='x', labelrotation=90);\n",
    "\n",
    "ax1.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax1.set_yticks(range(0, 80, 10));\n",
    "\n",
    "# ax1.get_legend().remove();\n",
    "# ax1.legend(['])\n",
    "ax1.legend(custom_lines, ['training', 'validation', 'median'], loc='upper left');\n",
    "ax1.grid();\n",
    "\n",
    "ax2.set_prop_cycle('color', colors)\n",
    "\n",
    "weekly_train_pivot.transpose().plot(style='-', linewidth=5, color=COL_TRAIN, alpha=0.2, ax=ax2);\n",
    "weekly_valid_pivot.iloc[-1].plot(style='-', linewidth=2, color=COL_VALID, alpha=1, ax=ax2);\n",
    "ax2.plot(weekly_train_med['Minuteofweek'], weekly_train_med['Moulin'], color=COL_MED, alpha=ALPHA);\n",
    "\n",
    "ax2.set_xticks([d*ONE_DAY*RESOL for d in range(0, 7)])\n",
    "ax2.set_xticklabels(days_of_the_week.values());\n",
    "ax2.set_xlabel(\"Day of week\", fontsize=14);\n",
    "ax2.tick_params(axis='x', labelrotation=90);\n",
    "\n",
    "ax2.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax2.set_yticks(range(0, 80, 10));\n",
    "\n",
    "ax2.legend(custom_lines, ['training', 'validation', 'average'], loc='upper right');\n",
    "ax2.grid();\n",
    "\n",
    "if SAVEFIGS:\n",
    "    plt.savefig('moulin-weekly-timeseries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing median and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), sharex=True);\n",
    "\n",
    "custom_lines = [ \n",
    "    #Line2D([0], [0], color=COL_TRAIN, lw=4),\n",
    "    Line2D([0], [0], color=COL_VALID, lw=4),\n",
    "    Line2D([0], [0], color=COL_AVG, lw=4),\n",
    "    Line2D([0], [0], color=COL_MED, lw=4),\n",
    "]\n",
    "\n",
    "ax1.set_prop_cycle('color', colors)\n",
    "\n",
    "#weekly_train_pivot.transpose().plot(style='-', linewidth=5, color=COL_TRAIN, alpha=0.2, ax=ax1);\n",
    "if weekly_valid_pivot.shape[0] > 1:\n",
    "    weekly_valid_pivot.iloc[-2].plot(style='-', linewidth=2, color=COL_VALID, alpha=1, ax=ax1);\n",
    "ax1.plot(weekly_train_avg['Minuteofweek'], weekly_train_avg['Moulin'], color=COL_AVG, alpha=ALPHA);\n",
    "ax1.plot(weekly_train_med['Minuteofweek'], weekly_train_med['Moulin'], color=COL_MED, alpha=ALPHA);\n",
    "\n",
    "\n",
    "ax1.set_title(\"Seat availability: weekly view (rue du Fer à Moulin)\", fontsize=18);\n",
    "\n",
    "ax1.set_xticks([d*ONE_DAY*RESOL for d in range(0, 7)])\n",
    "ax1.set_xticklabels(days_of_the_week.values());\n",
    "ax1.set_xlabel(\"Day of week\", fontsize=14);\n",
    "ax1.tick_params(axis='x', labelrotation=90);\n",
    "\n",
    "ax1.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax1.set_yticks(range(0, 80, 10));\n",
    "\n",
    "# ax1.get_legend().remove();\n",
    "# ax1.legend(['])\n",
    "ax1.legend(custom_lines, ['training', 'validation', 'median'], loc='upper left');\n",
    "ax1.grid();\n",
    "\n",
    "ax2.set_prop_cycle('color', colors)\n",
    "\n",
    "# weekly_train_pivot.transpose().plot(style='-', linewidth=5, color=COL_TRAIN, alpha=0.2, ax=ax2);\n",
    "weekly_valid_pivot.iloc[-1].plot(style='-', linewidth=2, color=COL_VALID, alpha=1, ax=ax2);\n",
    "ax2.plot(weekly_train_avg['Minuteofweek'], weekly_train_avg['Moulin'], color=COL_AVG, alpha=ALPHA);\n",
    "ax2.plot(weekly_train_med['Minuteofweek'], weekly_train_med['Moulin'], color=COL_AVG, alpha=ALPHA);\n",
    "\n",
    "\n",
    "ax2.set_xticks([d*ONE_DAY*RESOL for d in range(0, 7)])\n",
    "ax2.set_xticklabels(days_of_the_week.values());\n",
    "ax2.set_xlabel(\"Day of week\", fontsize=14);\n",
    "ax2.tick_params(axis='x', labelrotation=90);\n",
    "\n",
    "ax2.set_ylabel(\"Available seats\", fontsize=14);\n",
    "ax2.set_yticks(range(0, 80, 10));\n",
    "\n",
    "ax2.legend(custom_lines, ['training', 'validation', 'average'], loc='upper right');\n",
    "ax2.grid();\n",
    "\n",
    "if SAVEFIGS:\n",
    "    plt.savefig('moulin-weekly-timeseries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with heatmaps\n",
    "With the pivot tables from above we can also generate an alternattive representation of the data using heatmaps.  \n",
    "\n",
    "## Visualizing historical data with a heatmap\n",
    "We first view the entire dataset with a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 20));\n",
    "\n",
    "ax.set_facecolor(\"black\")\n",
    "mask = daily_pivot.sort_index(ascending=False).isnull()\n",
    "sns.heatmap(daily_pivot.sort_index(ascending=False),\n",
    "            cmap=\"Oranges_r\",\n",
    "            mask=mask,\n",
    "            ax=ax);\n",
    "\n",
    "ax.set_xlabel(\"Time of day\", fontsize=14);\n",
    "ax.set_xticks([h*ONE_HOUR for h in range(0, 24)]);\n",
    "ax.set_xlabel(\"Time of day\", fontsize=14);\n",
    "ax.set_xticks([h*ONE_HOUR for h in range(0, 24)]);\n",
    "ax.set_xticklabels([\"{0:02d}:00\".format(x//ONE_HOUR) for x in ax.get_xticks()])\n",
    "ax.tick_params(axis='x', labelrotation=45);\n",
    "\n",
    "ax.set_yticklabels([new_y_ticklabel(text) for text in ax.get_yticklabels()]);\n",
    "ax.set_ylabel(\"Date\", fontsize=14);\n",
    "ax.tick_params(axis='y', labelrotation=0);\n",
    "\n",
    "ax.set_title(\"Seat availability (rue du Fer à Moulin)\", fontsize=18);\n",
    "if SAVEFIGS:\n",
    "    plt.savefig(\"moulin-availability-heatmap.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting missing data\n",
    "\n",
    "The black cells represent missing data.  \n",
    "\n",
    "Some of these missing data were created while generating the pivot table.  Indeed, data was missing at the beginning of the first day of data collection, and data is not yet available for the remainder of the last day of data collection.  Let's set these values to `-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data at beginning of first day\n",
    "daily_pivot.iloc[0].fillna(value=-1, inplace=True)  \n",
    "# Missing data at end of last day\n",
    "daily_pivot.iloc[-1].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, there are missing data on Sun 31 Apr 2019.  These are actually due to the switch to daylight saving time in France, which occurs at 2am.  Let's find them in the pivot table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = np.where(daily_pivot.apply(axis=1, func=lambda x : any(pd.isnull(x))))\n",
    "nan_cols = np.where(daily_pivot.apply(axis=0, func=lambda x : any(pd.isnull(x))))\n",
    "len(nan_rows[0]), len(nan_cols[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains `1` row with `30` `nan` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pivot.iloc[nan_rows[0], nan_cols[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, these occur between 2am and 3am (between minute `2*60 = 120` and `3*60 = 180`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pivot.fillna(value=-1, inplace=True)\n",
    "daily_pivot = daily_pivot.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing averages with a heatmap\n",
    "To represent the average data, we calculate another pivot table (alternatively, we could have added a bit more to `weekly_avg` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg = train_data.groupby(['Dayofweek', 'Minuteofday']).apply(lambda x: x['Moulin'].mean().round().astype(np.uint8)).reset_index()\n",
    "train_avg.rename(columns={0: 'Moulin'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avg_pivot = pd.pivot_table(train_avg, index='Dayofweek', columns='Minuteofday', values='Moulin')\n",
    "train_avg_pivot.fillna(train_avg_pivot.mean(axis=0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE);\n",
    "\n",
    "sns.heatmap(train_avg_pivot.sort_index(ascending=False),\n",
    "          # annot=True,\n",
    "            cmap=\"Oranges_r\",\n",
    "            # linewidths=.5, fmt='.3g',\n",
    "            ax=ax);\n",
    "ax.set_xlabel(\"Time of day\", fontsize=14);\n",
    "ax.set_xticks([h*ONE_HOUR for h in range(0, 24)]);\n",
    "ax.set_xticklabels([\"{0:02d}:00\".format(x//ONE_HOUR) for x in ax.get_xticks()])\n",
    "ax.tick_params(axis='x', labelrotation=45);\n",
    "ax.set_yticklabels(days_of_the_week.values());\n",
    "ax.set_title(\"Average seat availability (rue du Fer à Moulin)\", fontsize=18);\n",
    "ax.set_ylabel(\"Day of week\", fontsize=14);\n",
    "ax.tick_params(axis='y', labelrotation=0);\n",
    "if SAVEFIGS:\n",
    "    plt.savefig('moulin-average-heatmap.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
